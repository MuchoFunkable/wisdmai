{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB and Reddit Data\n",
    "\n",
    "- test full scale reddit script \n",
    "- do pandas profile report\n",
    "\n",
    "- connect to mongdb cluster\n",
    "- browse databases\n",
    "- view collections\n",
    "- insert new datapoints \n",
    "- develop code to query data from previous day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Script Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.6.0 of praw is outdated. Version 7.6.1 was released 11 hours ago.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dramatic-Ad-9651\n",
      "wallstreetbets  -  AAPL\n",
      "stocks  -  AAPL\n",
      "investing  -  AAPL\n",
      "finance  -  AAPL\n",
      "wallstreetbets  -  BBBY\n",
      "stocks  -  BBBY\n",
      "investing  -  BBBY\n",
      "finance  -  BBBY\n",
      "wallstreetbets  -  AMD\n",
      "stocks  -  AMD\n",
      "investing  -  AMD\n",
      "finance  -  AMD\n",
      "wallstreetbets  -  SNAP\n"
     ]
    }
   ],
   "source": [
    "#### imports ####\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from praw.models import MoreComments\n",
    "import preprocessor as pre\n",
    "import regex as re\n",
    "\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"auD_kIwyQ1r3hfxTQEYuGw\",\n",
    "    client_secret=\"XyLGeMB1mJqoaB0lCXrk4Jtmy515AA\",\n",
    "    password=\"wisdmai1234\",\n",
    "    user_agent=\"wisdm\",\n",
    "    username=\"Dramatic-Ad-9651\",\n",
    "    check_for_async=False\n",
    ")\n",
    "\n",
    "# make sure we're connected to the api\n",
    "print(reddit.user.me())\n",
    "\n",
    "\n",
    "#### Data Extraction #### \n",
    "\n",
    "posts = pd.DataFrame()\n",
    "comments = pd.DataFrame()\n",
    "\n",
    "tickers = tickers = list(set(['SPY','TSLA','PYPL', 'GME', 'VIX', 'AMD', 'F',\n",
    "                              'BBBY', 'NFLX', 'NVDA', 'AAPL', 'INTC', 'FSR', \n",
    "                              'QQQ', 'TLRY', 'MSFT', 'TWTR', 'SNAP', 'HOOD', \n",
    "                              'WMT', 'PTON', 'WISH', 'CPRX', 'AMC', 'SNDL', \n",
    "                              'AMZN', 'DIS', 'NIO', 'FB', 'NFLX', 'LCID', 'NVDA']))\n",
    "\n",
    "\n",
    "subreddits = ['wallstreetbets', 'stocks',  'investing', 'finance']\n",
    "\n",
    "\n",
    "for ticker in tickers: \n",
    "    for sub in subreddits: \n",
    "        subreddit = reddit.subreddit(sub)\n",
    "        print(subreddit, ' - ', ticker)\n",
    "        for post in subreddit.search(ticker.lower(), sort = 'new', time_filter = 'day', limit = None):\n",
    "            #check if title has stock ticker \n",
    "            if ticker.lower() not in post.title.lower(): \n",
    "                #print(post.title)\n",
    "                continue \n",
    "            #check if author is not banned \n",
    "            if hasattr(post.author, 'is_suspended'):\n",
    "                #print(post.author.is_suspended)\n",
    "                continue\n",
    "            try: \n",
    "                #collect desired values \n",
    "                title_instance = {\n",
    "                    'ticker': ticker, \n",
    "                    'subreddit': str(post.subreddit),\n",
    "                    'content': post.title, \n",
    "                    'upvotes': post.score, \n",
    "                    'upvote_ratio': post.upvote_ratio,\n",
    "                    'num_comments': post.num_comments, \n",
    "                    #might break in author deletes their post \n",
    "                    'author_comment_karma': post.author.comment_karma, \n",
    "                    'author_verified': post.author.has_verified_email, \n",
    "                    'time': datetime.fromtimestamp(post.created_utc).strftime('%Y-%m-%d'),\n",
    "                }\n",
    "            \n",
    "            except: \n",
    "                continue \n",
    "\n",
    "            #create row and concat it to the df\n",
    "            row = pd.DataFrame([title_instance])\n",
    "            posts = pd.concat([posts, row], axis = 0, ignore_index = True)\n",
    "\n",
    "            #checking comments\n",
    "            for comment in post.comments:\n",
    "                #do not want sub comments of comments \n",
    "                if isinstance(comment, MoreComments):\n",
    "                    continue\n",
    "                #remove user reports\n",
    "                if 'user report' in comment.body.lower(): \n",
    "                    continue\n",
    "                \n",
    "                try: \n",
    "                    comment_instance = {\n",
    "                        'ticker': ticker, \n",
    "                        'subreddit': str(post.subreddit), \n",
    "                        # optional can remove if no grouping by title is needed \n",
    "                        'post_title': post.title,\n",
    "                        'content': comment.body, \n",
    "                        'upvotes': comment.score, \n",
    "                        'replies': comment.replies.__len__(), \n",
    "                        'sticked': comment.stickied,\n",
    "                        #might break deleted comments\n",
    "                        'author_comment_karma': comment.author.comment_karma, \n",
    "                        'author_verified': comment.author.has_verified_email, \n",
    "                        'time': datetime.fromtimestamp(comment.created_utc).strftime('%Y-%m-%d'),\n",
    "                    }\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                row = pd.DataFrame([comment_instance])\n",
    "                comments = pd.concat([comments, row], axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "#### Data Export #### \n",
    "\n",
    "\n",
    "comments_df = comments.copy()\n",
    "posts_df = posts.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#comments_export_path = r\"C:\\Users\\Dennis\\Desktop\\comments.csv\"\n",
    "#comments_df.to_csv(comments_export_path)\n",
    "\n",
    "#posts_export_path = r\"C:\\Users\\Dennis\\Desktop\\posts.csv\"\n",
    "#posts_df.to_csv(posts_export_path)\n",
    "\n",
    "print('Data Exported')\n",
    "print(\"Posts\", len(posts_df))\n",
    "print(\"Comments:\", len(comments_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to MongoDB using PyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"mongodb+srv://wisdmDev:TtFyq1MMqmkp4ZAg@wisdmdev.4fwfwiz.mongodb.net/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(connection, tlsCAFILE = certifi.where())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_airbnb = client['sample_airbnb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_airbnb.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsAndReviews = sample_airbnb['listingsAndReviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsAndReviews.find_one()['listing_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Database and making sure they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditDb = client['Reddit'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = redditDb['posts']\n",
    "comments = redditDb['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.insert_one({'test':'hi'})\n",
    "comments.insert_one({'test':'hi'})\n",
    "\n",
    "posts.delete_many({})\n",
    "comments.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditDb.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure it's empty\n",
    "list(posts.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(comments.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count before insert\n",
    "posts.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dict = posts_df.to_dict('records')\n",
    "len(post_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.insert_many(post_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6137767cd5a1185f0adfe5ac38846a9103bfc8540bec40d423695759fa94714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
